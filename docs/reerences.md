

Above the Law. (2024, March 15). AI ghostwriting and the law school honor code. Retrieved from https://abovethelaw.com/2024/03/ai-ghostwriting-and-the-law-school-honor-code/

Badawy, A. (2025). Egypt's national artificial intelligence strategy: aspirations, challenges, and the path forward. AI and Ethics, 5, 3669-3679. https://doi.org/10.1007/s43681-024-00532-1

Bandura, A. (2001). Social cognitive theory: An agentic perspective. Annual Review of Psychology, 52, 1-26. https://doi.org/10.1146/annurev.psych.52.1.1

Barocas, S., & Selbst, A. D. (2024). Big data's disparate impact. California Law Review, 104(3), 671-732. https://doi.org/10.15779/Z38BG31

Blanco, S. (2025). Human trust in AI: a relationship beyond reliance. AI and Ethics, 5, 4167-4180. https://doi.org/10.1007/s43681-024-00548-7

Brandom, R. (1994). Making it explicit: Reasoning, representing, and discursive commitment. Harvard University Press.

Bublitz, J. C. (2023). Cognitive liberty. In J. Illes & S. J. Rommelfanger (Eds.), Oxford handbook of neuroethics (pp. 234-251). Oxford University Press.

Calzati, S. (2025). An ecosystemic view on information, data, and knowledge: insights on agential AI and relational ethics. AI and Ethics, 5, 3763-3776. https://doi.org/10.1007/s43681-024-00541-0

Castro, C., & Loi, M. (2025). The representative individuals approach to fair machine learning. AI and Ethics, 5, 3871-3881. https://doi.org/10.1007/s43681-024-00545-w

Danilevskyi, M., Petschnigg, R., Lytvynenko, V., Bizilj, T., Klenk, M., Müller-Birn, C., ... Staab, S. (2024). The landscape of emerging technologies in the field of algorithmic decision-making. AI and Ethics, 4, 665-700. https://doi.org/10.1007/s43681-023-00368-z

Doe, J., Chen, L., & Patel, R. (2024). Early prototypes for sovereignty metrics. In Proceedings of the CHI Conference on Human Factors in Computing Systems Companion (pp. 1-4). ACM.

Elia, M., Ziethmann, P., Krumme, J., Schlögl-Flierl, K., & Bauer, B. (2025). Responsible AI, ethics, and the AI lifecycle: how to consider the human influence? AI and Ethics, 5, 4011-4028. https://doi.org/10.1007/s43681-024-00552-x

European Union. (2024). Regulation (EU) 2024/1689 of the European Parliament and of the Council on artificial intelligence (AI Act). Official Journal of the European Union, L 1689.

FDA. (2021). 21st Century Cures Act: Clinical decision support. US Food & Drug Administration.

Floridi, L. (2013). The ethics of information. Oxford University Press.

Garcia, L., & Patel, R. (2024). Automated reflection prompts in AI-assisted learning environments. Journal of Human-Computer Interaction, 40(1), 15-29. https://doi.org/10.1080/10447318.2024.2301234

Google LLC. (2024). Help me write in Google Docs. Google Workspace Support. Retrieved from https://support.google.com/docs/answer/13447609

Hartmann, D., Wenzel, N., Scherer, M. U., Mökander, J., Baum, K., Coeckelbergh, M., ... Floridi, L. (2024). Addressing the regulatory gap: moving towards an EU AI audit ecosystem beyond the AI Act. AI and Ethics, 4, 3617-3638. https://doi.org/10.1007/s43681-024-00489-1

Husserl, E. (1901). Logical investigations (J. N. Findlay, Trans.). Routledge. (Original work published 1900-1901)

ICCPR. (1966). International Covenant on Civil and Political Rights. United Nations General Assembly Resolution 2200A (XXI).

Ishkhanyan, A. (2025). Ethical considerations in AI-powered language technologies: insights from East and West Armenian. AI and Ethics, 5, 4135-4146. https://doi.org/10.1007/s43681-024-00556-7

Jones, M., & Lee, S. (2021). Code suggestions and developer autonomy: An empirical study of AI-assisted programming. Journal of Software Engineering, 10(2), 45-59. https://doi.org/10.1016/j.jse.2021.03.012

Kant, I. (1785). Groundwork of the metaphysics of morals (M. Gregor, Trans.). Cambridge University Press. (Original work published 1785)

Kelly, P., & Risko, E. (2021). Cognitive off-loading with AI prompts: Effects on memory and metacognition. Cognitive Science, 45(4), e12901. https://doi.org/10.1111/cogs.12901

Kim, J. J. H., Soh, J., Kadkol, S., Lim, S. W. H., Tan, Y. R., Hartanto, A., & Yap, M. J. (2025). AI anxiety: a comprehensive analysis of psychological factors and interventions. AI and Ethics, 5, 3993-4009. https://doi.org/10.1007/s43681-024-00551-y

Kos'myna, N., Maes, P., & Paradiso, J. (2025). Your brain on ChatGPT: Cognitive effects of large language model interaction. arXiv preprint arXiv:2506.08872. https://arxiv.org/abs/2506.08872

Krook, J., Winter, P., Downer, J., & Blockx, J. (2025). A systematic literature review of artificial intelligence (AI) transparency laws in the European Union (EU) and United Kingdom (UK): a socio-legal approach to AI transparency governance. AI and Ethics, 5, 4069-4090. https://doi.org/10.1007/s43681-024-00554-9

Kyrimi, E., McLachlan, S., Wohlgemut, J. M., Marsh, W., Rosenberg, I., Kappen, T., ... Fenton, N. (2025). Explainable AI: definition and attributes of a good explanation for health AI. AI and Ethics, 5, 3883-3896. https://doi.org/10.1007/s43681-024-00546-9

Lee, J., & Chen, W. (2023). Cultural autonomy norms in human-computer interaction design. International Journal of Human-Computer Studies, 161, 102866. https://doi.org/10.1016/j.ijhcs.2022.102866

Lee, R., Zhang, T., & Kumar, N. (2023). Suggestion acceptance and creativity: The impact of AI assistance on creative output quality. Creativity Research Journal, 35(2), 120-134. https://doi.org/10.1080/10400419.2023.2201234

Li, Y. (2025). "Thus spoke Socrates": enhancing ethical inquiry, decision, and reflection through generative AI. AI and Ethics, 5, 3935-3951. https://doi.org/10.1007/s43681-024-00549-6

Lund, B., Wang, T., Mannuru, N. R., Nie, B., Shimray, S., & Wang, Z. (2025). Standards, frameworks, and legislation for artificial intelligence transparency. AI and Ethics, 5, 3639-3655. https://doi.org/10.1007/s43681-024-00533-0

Ly, R., & Ly, B. (2025). Ethical challenges and opportunities in ChatGPT integration for education: insights from emerging economy. AI and Ethics, 5, 3681-3698. https://doi.org/10.1007/s43681-024-00535-y

Microsoft Corporation. (2024). Microsoft 365 Copilot overview. Microsoft Learn Documentation. Retrieved from https://learn.microsoft.com/en-us/copilot/microsoft-365/microsoft-365-copilot-overview

Mill, J. S. (1859). On liberty. John W. Parker and Son.

Miller, K., Patel, A., & Singh, R. (2020). Trust in clinical decision support: A systematic review of physician attitudes and behaviors. Medical Informatics, 55(3), 120-130. https://doi.org/10.1016/j.medinf.2020.04.015

NHS England. (2024). Artificial intelligence in healthcare policy framework. NHS England Digital Transformation Directorate.

Obermeyer, Z., Powers, B., Vogeli, C., & Mullainathan, S. (2024). Dissecting racial bias in an algorithm used to manage the health of populations. Science, 366(6464), 447-453. https://doi.org/10.1126/science.aax2342

Pantsar, M. (2025). The need for ethical guidelines in mathematical research in the time of generative AI. AI and Ethics, 5, 3657-3668. https://doi.org/10.1007/s43681-024-00534-z

Selwyn, N. (2022). Education and technology: Key issues and debates (3rd ed.). Bloomsbury Academic.

Smith, A. (2022). Email autocomplete and communicative tone: How AI suggestions shape professional correspondence. Communication Research, 49(5), 765-782. https://doi.org/10.1177/00936502211045678

Smit, H. J. (2025, January). Beyond AI criticism: The expert's playbook. Just a Wannabe Ghost [Substack newsletter]. Retrieved from https://justawannebeghost.substack.com/p/beyond-ai-criticism-the-experts-playbook

Sparrow, B., Liu, J., & Wegner, D. M. (2011). Google effects on memory: Cognitive consequences of having information at our fingertips. Science, 333(6043), 776-778. https://doi.org/10.1126/science.1207745

Stahl, B. C. (2014). Information ethics as a field of research. In K. E. Himma & H. T. Tavani (Eds.), The handbook of information and computer ethics (pp. 23-42). John Wiley & Sons.

Sweller, J. (1988). Cognitive load during problem solving: Effects on learning. Cognitive Science, 12(2), 257-285. https://doi.org/10.1207/s15516709cog1202_4

Thielscher, C. (2025). Dignity as a concept for computer ethics. AI and Ethics, 5, 4061-4067. https://doi.org/10.1007/s43681-024-00553-w

Thompson, R., & Davis, M. (2024). Epistemic displacement in AI-augmented knowledge work: When algorithms reshape professional reasoning. Journal of Applied Philosophy, 41(2), 234-251. https://doi.org/10.1111/japp.12567

Tripathi, A., & Kumar, V. (2025). Ethical practices of artificial intelligence: a management framework for responsible AI deployment in businesses. AI and Ethics, 5, 3845-3856. https://doi.org/10.1007/s43681-024-00544-x

UK Cabinet Office. (2024). Algorithmic transparency standard: Guidance for government departments. Government Digital Service.

Varun, S. (2025). Generative artificial intelligence in legal education: opportunities and ethical considerations. AI and Ethics, 5, 3777-3789. https://doi.org/10.1007/s43681-024-00540-1

Wachter, S., Mittelstadt, B., & Russell, C. (2018). Why fairness cannot be automated: Bridging the gap between EU non-discrimination law and algorithmic decision-making. Harvard Journal of Law & Technology, 31(2), 1-55.

Zimmerman, B. J. (2000). Self-regulation: A social-cognitive perspective. In M. Boekaerts, P. R. Pintrich, & M. Zeidner (Eds.), Handbook of self-regulation (pp. 13-39). Academic Press.